algo: "ppo"

env:
  id: "SlicingEnv-v0"
  num_envs: 1

training:
  total_timesteps: 100000
  learning_rate: 3.0e-4
  n_steps: 2048
  batch_size: 64
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5

logging:
  log_interval: 10
  save_freq: 10000
  checkpoint_dir: "data/checkpoints/ppo"
